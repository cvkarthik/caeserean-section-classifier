{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  'Age'  'Delivery  'Delivery.1  'Blood  'Heart  Caesarian\n",
       "0   1     22          1            0       2       0          0\n",
       "1   2     26          2            0       1       0          1\n",
       "2   3     26          2            1       1       0          0\n",
       "3   4     28          1            0       2       0          0\n",
       "4   5     22          2            0       1       0          1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>'Age'</th>\n      <th>'Delivery</th>\n      <th>'Delivery.1</th>\n      <th>'Blood</th>\n      <th>'Heart</th>\n      <th>Caesarian</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>22</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>26</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>26</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>28</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>22</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('csv_result-caesarian.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            id      'Age'  'Delivery  'Delivery.1     'Blood     'Heart  \\\n",
       "count  80.0000  80.000000  80.000000    80.000000  80.000000  80.000000   \n",
       "mean   40.5000  27.687500   1.662500     0.637500   1.000000   0.375000   \n",
       "std    23.2379   5.017927   0.794662     0.815107   0.711568   0.487177   \n",
       "min     1.0000  17.000000   1.000000     0.000000   0.000000   0.000000   \n",
       "25%    20.7500  25.000000   1.000000     0.000000   0.750000   0.000000   \n",
       "50%    40.5000  27.000000   1.000000     0.000000   1.000000   0.000000   \n",
       "75%    60.2500  32.000000   2.000000     1.000000   1.250000   1.000000   \n",
       "max    80.0000  40.000000   4.000000     2.000000   2.000000   1.000000   \n",
       "\n",
       "       Caesarian  \n",
       "count  80.000000  \n",
       "mean    0.575000  \n",
       "std     0.497462  \n",
       "min     0.000000  \n",
       "25%     0.000000  \n",
       "50%     1.000000  \n",
       "75%     1.000000  \n",
       "max     1.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>'Age'</th>\n      <th>'Delivery</th>\n      <th>'Delivery.1</th>\n      <th>'Blood</th>\n      <th>'Heart</th>\n      <th>Caesarian</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>80.0000</td>\n      <td>80.000000</td>\n      <td>80.000000</td>\n      <td>80.000000</td>\n      <td>80.000000</td>\n      <td>80.000000</td>\n      <td>80.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>40.5000</td>\n      <td>27.687500</td>\n      <td>1.662500</td>\n      <td>0.637500</td>\n      <td>1.000000</td>\n      <td>0.375000</td>\n      <td>0.575000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>23.2379</td>\n      <td>5.017927</td>\n      <td>0.794662</td>\n      <td>0.815107</td>\n      <td>0.711568</td>\n      <td>0.487177</td>\n      <td>0.497462</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.0000</td>\n      <td>17.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>20.7500</td>\n      <td>25.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.750000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>40.5000</td>\n      <td>27.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>60.2500</td>\n      <td>32.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.250000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>80.0000</td>\n      <td>40.000000</td>\n      <td>4.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(80, 5)\n(80, 1)\n[[22  1  0  2  0]\n [26  2  0  1  0]\n [26  2  1  1  0]\n [28  1  0  2  0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "Xc=df.columns[0:]\n",
    "X=df[Xc[1:6]].values\n",
    "Y=df[Xc[6]].values\n",
    "Y=Y.reshape(80,1)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.1,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.26  0.09  1.01 -0.15 -0.94  3.34]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron(object):\n",
    "    def __init__(self,eta=0.01,n_iter=10):\n",
    "        self.eta=eta\n",
    "        self.n_iter=n_iter\n",
    "    def fit(self,X,y):  #to train\n",
    "        self.w_=np.zeros(1+X.shape[1])  # weights and bias shapereturns dimension as tuple\n",
    "        for _ in range(self.n_iter):\n",
    "            for xi, target in zip(X,y):  #zip used to unfold value in two arrays one by one\n",
    "                error=target-self.predict(xi)\n",
    "                if error!=0:\n",
    "                    update = self.eta * (target-self.predict(xi))\n",
    "                    self.w_[1:] += update * xi\n",
    "                    self.w_[0] += update*1\n",
    "        return self\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >=0.0, 1, 0)\n",
    "ob=Perceptron(eta=0.01,n_iter=60)\n",
    "ob.fit(X_train,y_train)\n",
    "print(ob.w_)\n",
    "res=ob.predict(X_test)\n",
    "restrain=ob.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of training data:56.94444444444444\nAccuracy of testing data:62.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of training data:'+str(accuracy_score(y_train,restrain)*100))\n",
    "print('Accuracy of testing data:'+str(accuracy_score(y_test,res)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', C=100, random_state=0)\n",
    "svm.fit(X_train, y_train)\n",
    "y_predtrain=svm.predict(X_train)\n",
    "y_predtest=svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of training data:73.4375\nAccuracy of testing data:75.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of training data:'+str(accuracy_score(y_train,y_predtrain)*100))\n",
    "print('Accuracy of testing data:'+str(accuracy_score(y_test,y_predtest)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LVQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def LVQ(x,tar):\n",
    "    W=np.zeros((2,x.shape[1]))\n",
    "    lr=0.5\n",
    "    d=[0,0]\n",
    "    e=1\n",
    "    while(e<=10):\n",
    "      for i in range(x.shape[0]):\n",
    "        for j in range(W.shape[0]):\n",
    "          d[j]=np.sum((x[i,:]-W[j,:])**2)\n",
    "          d[j]=d[j]**0.5\n",
    "        if(d[0]<d[1]):\n",
    "          t=0\n",
    "          #print(\"winning neuron is \",0)\n",
    "        else:\n",
    "          t=1\n",
    "          #print(\"winning neuron is\", 1)\n",
    "        if(t==tar[i]):\n",
    "          W[t,:]+=lr*(x[i,:]-W[t,:])\n",
    "        else:\n",
    "           W[t,:]-=lr*(x[i,:]-W[t,:])\n",
    "      print(\"Updated weights at epoch \",e,\"are \",W)\n",
    "      e+=1\n",
    "      lr=0.5*lr\n",
    "      \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Updated weights at epoch  1 are  [[-8.86079673e+01 -7.67827761e+00  4.00379241e+00 -3.56223583e-01\n  -6.83013582e+00]\n [ 3.41816080e+01  3.64330975e+00 -5.23903051e-02  1.56153710e+00\n   6.14453898e-01]]\nUpdated weights at epoch  2 are  [[-88.60796726  -7.67827761   4.00379241  -0.35622358  -6.83013582]\n [ 34.48543569   3.5661211    0.21155177   1.2447972    1.01698491]]\nUpdated weights at epoch  3 are  [[-88.60796726  -7.67827761   4.00379241  -0.35622358  -6.83013582]\n [ 33.05183089   3.12434043   0.21762412   1.05558098   1.16090668]]\nUpdated weights at epoch  4 are  [[-88.60796726  -7.67827761   4.00379241  -0.35622358  -6.83013582]\n [ 32.16579867   2.89957248   0.18774867   0.96308113   1.18821946]]\nUpdated weights at epoch  5 are  [[-88.60796726  -7.67827761   4.00379241  -0.35622358  -6.83013582]\n [ 31.7455278    2.80156625   0.16813462   0.91752718   1.19999349]]\nUpdated weights at epoch  6 are  [[-88.60796726  -7.67827761   4.00379241  -0.35622358  -6.83013582]\n [ 31.54452195   2.75681888   0.15733994   0.89477217   1.2062092 ]]\nUpdated weights at epoch  7 are  [[-88.60796726  -7.67827761   4.00379241  -0.35622358  -6.83013582]\n [ 31.44654488   2.73554665   0.15170613   0.88337563   1.20947931]]\nUpdated weights at epoch  8 are  [[-88.60796726  -7.67827761   4.00379241  -0.35622358  -6.83013582]\n [ 31.39820936   2.72518858   0.14883078   0.87766929   1.21116391]]\nUpdated weights at epoch  9 are  [[-88.60796726  -7.67827761   4.00379241  -0.35622358  -6.83013582]\n [ 31.37420706   2.72007928   0.14737853   0.87481367   1.21201966]]\nUpdated weights at epoch  10 are  [[-88.60796726  -7.67827761   4.00379241  -0.35622358  -6.83013582]\n [ 31.36224753   2.71754208   0.14664877   0.8733852    1.21245103]]\n"
     ]
    }
   ],
   "source": [
    "W=LVQ(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-88.60796726  -7.67827761   4.00379241  -0.35622358  -6.83013582]\n [ 31.36224753   2.71754208   0.14664877   0.8733852    1.21245103]]\n[[-88.60796726  -7.67827761   4.00379241  -0.35622358  -6.83013582]\n [ 31.36224753   2.71754208   0.14664877   0.8733852    1.21245103]]\nAccuracy:59.375\nAccuracy:50.0\n"
     ]
    }
   ],
   "source": [
    "def LVQt(X,Y,W):\n",
    "    d=[0,0]\n",
    "    print(W)\n",
    "    res=np.zeros(Y.shape)\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(W.shape[0]):\n",
    "            d[j]=np.sum((X[i,:]-W[j,:])**2)\n",
    "            d[j]=d[j]**0.5\n",
    "        if d[0]<d[1]:\n",
    "            res[i]=0\n",
    "        else:\n",
    "            res[i]=1\n",
    "    return res\n",
    "y_predtrain=LVQt(X_train,y_train,W)\n",
    "y_pred=LVQt(X_test,y_test,W)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy:'+str(accuracy_score(y_train,y_predtrain)*100))\n",
    "print('Accuracy:'+str(accuracy_score(y_test,y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#x=np.array([[0,0,1,1],[1,1,0,0]])\n",
    "def SOM(x,y):\n",
    "    W=np.zeros((2,x.shape[1]))\n",
    "    lr=1\n",
    "    d=[0,0]\n",
    "    e=1\n",
    "    res=np.zeros(y.shape)\n",
    "    while(e<=10):\n",
    "      for i in range(x.shape[0]):\n",
    "        for j in range(W.shape[0]):\n",
    "          d[j]=np.sum((x[i,:]-W[j,:])**2)\n",
    "          d[j]=d[j]**0.5\n",
    "        print(d)\n",
    "        if(d[0]<d[1]):\n",
    "          t=0\n",
    "          res[i]=0\n",
    "          #print(\"winning neuron is \",0)\n",
    "        else:\n",
    "          t=1\n",
    "          res[i]=1\n",
    "          #print(\"winning neuron is\", 1)\n",
    "        W[t,:]+=lr*(x[i,:]-W[t,:])\n",
    "      print(\"Updated weight at epoch \",e,\"are \",W)\n",
    "      e+=1\n",
    "      lr=0.5*lr\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4379907536]\n[25.03996805109783, 2.4451892853525954]\n[21.142374511865974, 5.751421230299863]\n[26.057628441590765, 1.142403586514523]\n[38.23610858861032, 12.828118165118056]\n[28.089143810376278, 1.3892531135996755]\n[20.074859899884732, 8.519212086070786]\n[18.05547008526779, 8.375406899624842]\n[31.144823004794873, 6.968518165720404]\n[26.038433132583073, 1.1032650449248864]\n[26.115129714401192, 1.9181615681479423]\n[35.07135583350036, 9.133125081495853]\n[26.095976701399778, 2.6841008045641312]\n[23.065125189341593, 4.707419506442139]\n[17.029386365926403, 9.588629939330037]\n[33.04542328371661, 8.89654822452985]\n[33.075670817082454, 6.853650071827037]\n[27.055498516937366, 1.2899783388761452]\n[33.25657829663178, 5.950697492420811]\n[29.103264421710495, 0.9573458797732114]\n[31.160872901765764, 3.0330966067178]\n[32.14031735997639, 2.7679555165883563]\n[36.29049462324811, 6.317131915169289]\nUpdated weight at epoch  3 are  [[ 0.          0.          0.          0.          0.        ]\n [31.61472064  2.34621156  0.4239168   1.51525142  0.74147601]]\n[28.089143810376278, 3.9803221230883366]\n[25.11971337416094, 6.353361191191523]\n[32.155870381627054, 2.1079365743628693]\n[18.193405398660254, 12.678542775979885]\n[36.08323710533743, 7.1060654392687805]\n[31.0322412983658, 1.7211020130568235]\n[19.05255888325765, 11.090404813611189]\n[24.186773244895647, 4.9662157202541]\n[25.099800796022265, 3.190244887156898]\n[20.223748416156685, 7.890451137275875]\n[22.20360331117452, 4.976436897435049]\n[32.0624390837628, 6.142761810137847]\n[27.09243436828813, 0.9459299469375586]\n[32.17141588429082, 5.513826922197288]\n[32.17141588429082, 4.736491482877364]\n[22.11334438749598, 6.127201108757112]\n[27.110883423451916, 0.9368598079918506]\n[35.02855977627399, 7.884029328319935]\n[32.09361307176243, 4.079251469940694]\n[33.03028912982749, 4.534481399682634]\n[21.02379604162864, 8.358680778898352]\n[27.03701166919155, 1.784362085621942]\n[36.02776706930364, 7.974670475579588]\n[40.0374824383352, 10.976718534977955]\n[22.045407685048602, 8.456032125216945]\n[19.05255888325765, 10.391678648766273]\n[26.095976701399778, 2.2375929858396835]\n[32.14031735997639, 4.439976634949468]\n[27.110883423451916, 1.7019064721299029]\n[29.103264421710495, 2.3111206433259888]\n[29.103264421710495, 1.1899937899276563]\n[24.124676163629637, 4.778962509016354]\n[26.13426869074396, 1.995478248752716]\n[29.086079144497972, 1.8615673254511718]\n[20.149441679609886, 7.927542254922509]\n[28.231188426986208, 2.3857683787248756]\n[37.14835124201342, 10.15296825182455]\n[22.11334438749598, 6.389331513941518]\n[25.099800796022265, 3.2890003997148693]\n[25.099800796022265, 2.8778753497505107]\n[26.038433132583073, 1.4467002059497949]\n[30.166206257996713, 3.5720574308984663]\n[25.03996805109783, 2.4166762953285432]\n[21.142374511865974, 6.018727144239604]\n[26.057628441590765, 0.8211503431001946]\n[38.23610858861032, 12.095923494892583]\n[28.089143810376278, 1.159811636301683]\n[20.074859899884732, 7.761305854367609]\n[18.05547008526779, 8.772167854612542]\n[31.144823004794873, 5.591888195349184]\n[26.038433132583073, 1.1073406626716724]\n[26.115129714401192, 1.8643456822073423]\n[35.07135583350036, 8.846081824959052]\n[26.095976701399778, 1.9921840879802195]\n[23.065125189341593, 4.207397128367796]\n[17.029386365926403, 9.727002380840025]\n[33.04542328371661, 7.5920048110201765]\n[33.075670817082454, 6.797489047970148]\n[27.055498516937366, 0.7213310411465841]\n[33.25657829663178, 6.435681201671856]\n[29.103264421710495, 1.4846978787879552]\n[31.160872901765764, 3.647099836880908]\n[32.14031735997639, 3.845316047549092]\n[36.29049462324811, 7.5977219832723595]\nUpdated weight at epoch  4 are  [[ 0.          0.          0.          0.          0.        ]\n [29.75383594  1.9663439   0.5144975   1.23682398  0.5544379 ]]\n[28.089143810376278, 2.27251132339522]\n[25.11971337416094, 4.841444687610768]\n[32.155870381627054, 2.989375037132695]\n[18.193405398660254, 11.601056596959166]\n[36.08323710533743, 7.3137673962624135]\n[31.0322412983658, 2.0935703234085206]\n[19.05255888325765, 10.41461128994226]\n[24.186773244895647, 4.987568398001489]\n[25.099800796022265, 3.510917710057666]\n[20.223748416156685, 8.40245452237558]\n[22.20360331117452, 5.940471418146215]\n[32.0624390837628, 4.941140272883827]\n[27.09243436828813, 1.0594652556971784]\n[32.17141588429082, 4.845032408745935]\n[32.17141588429082, 4.419487328285421]\n[22.11334438749598, 6.167437193678476]\n[27.110883423451916, 1.1663480187960908]\n[35.02855977627399, 7.47495633318602]\n[32.09361307176243, 4.129247948697882]\n[33.03028912982749, 4.851711065562513]\n[21.02379604162864, 7.816006675141495]\n[27.03701166919155, 1.9005271894423783]\n[36.02776706930364, 7.926837660717163]\n[40.0374824383352, 11.426630607187418]\n[22.045407685048602, 7.372414988437218]\n[19.05255888325765, 9.898847553886487]\n[26.095976701399778, 2.368306605660181]\n[32.14031735997639, 4.122664120107113]\n[27.110883423451916, 1.6194838860120204]\n[29.103264421710495, 2.2307723921687574]\n[29.103264421710495, 1.1296284833995218]\n[24.124676163629637, 4.7943358661134505]\n[26.13426869074396, 2.251596564193959]\n[29.086079144497972, 1.6389920545258247]\n[20.149441679609886, 8.155448700681331]\n[28.231188426986208, 2.0111090418287447]\n[37.14835124201342, 9.57043452277882]\n[22.11334438749598, 6.305204668700605]\n[25.099800796022265, 3.4586819357776277]\n[25.099800796022265, 3.2425143147915265]\n[26.038433132583073, 1.89973287863353]\n[30.166206257996713, 3.006602611829854]\n[25.03996805109783, 2.6923908467563487]\n[21.142374511865974, 6.465814606740325]\n[26.057628441590765, 1.2659017921654105]\n[38.23610858861032, 11.354156612997677]\n[28.089143810376278, 1.0430846737530624]\n[20.074859899884732, 7.689322802148412]\n[18.05547008526779, 9.19029251452885]\n[31.144823004794873, 4.689918245994587]\n[26.038433132583073, 1.3196437676252584]\n[26.115129714401192, 2.014357744168934]\n[35.07135583350036, 8.319841858870955]\n[26.095976701399778, 1.9260342929161007]\n[23.065125189341593, 4.240917565308375]\n[17.029386365926403, 10.005236465047007]\n[33.04542328371661, 6.739418837648668]\n[33.075670817082454, 6.4488454453817035]\n[27.055498516937366, 0.7252756539720421]\n[33.25657829663178, 6.4722128388183044]\n[29.103264421710495, 1.8284188637144]\n[31.160872901765764, 3.987808651425303]\n[32.14031735997639, 4.4547381541656375]\n[36.29049462324811, 8.405194665659142]\nUpdated weight at epoch  5 are  [[ 0.          0.          0.          0.          0.        ]\n [28.54074663  1.76092701  0.57100372  1.08813153  0.47000648]]\n[28.089143810376278, 1.4999574245237226]\n[25.11971337416094, 3.7614122953240616]\n[32.155870381627054, 3.8796709724244764]\n[18.193405398660254, 10.61284589747249]\n[36.08323710533743, 7.906081433416521]\n[31.0322412983658, 2.758122723314048]\n[19.05255888325765, 9.572661973731913]\n[24.186773244895647, 4.5023600015206]\n[25.099800796022265, 3.1922498032006392]\n[20.223748416156685, 8.201508463921401]\n[22.20360331117452, 6.012263898960337]\n[32.0624390837628, 4.673700592113451]\n[27.09243436828813, 1.0828914817540976]\n[32.17141588429082, 4.733316293601734]\n[32.17141588429082, 4.472422688523176]\n[22.11334438749598, 5.997241005894289]\n[27.110883423451916, 1.1874957172780518]\n[35.02855977627399, 7.410960046602707]\n[32.09361307176243, 4.288307233471575]\n[33.03028912982749, 5.1193908076096974]\n[21.02379604162864, 7.390458791595001]\n[27.03701166919155, 1.8191173410952604]\n[36.02776706930364, 8.067979685958319]\n[40.0374824383352, 11.808705427186284]\n[22.045407685048602, 6.6636604872136225]\n[19.05255888325765, 9.437109930570317]\n[26.095976701399778, 2.230836603229006]\n[32.14031735997639, 4.178674583206687]\n[27.110883423451916, 1.399734031739699]\n[29.103264421710495, 2.2319825082759177]\n[29.103264421710495, 1.2348125197931785]\n[24.124676163629637, 4.633193603813172]\n[26.13426869074396, 2.21525747032083]\n[29.086079144497972, 1.6667795666491116]\n[20.149441679609886, 8.144271571873876]\n[28.231188426986208, 1.88994764491212]\n[37.14835124201342, 9.356096031564805]\n[22.11334438749598, 6.216925256034985]\n[25.099800796022265, 3.5083416460755243]\n[25.099800796022265, 3.398705969635663]\n[26.038433132583073, 2.1429415187479157]\n[30.166206257996713, 2.706839962310336]\n[25.03996805109783, 2.8814108063593964]\n[21.142374511865974, 6.7540454068985705]\n[26.057628441590765, 1.6610907411498448]\n[38.23610858861032, 10.869917293537934]\n[28.089143810376278, 0.9173466161267634]\n[20.074859899884732, 7.793248220514124]\n[18.05547008526779, 9.52986157475515]\n[31.144823004794873, 4.111867354940143]\n[26.038433132583073, 1.6294128294009094]\n[26.115129714401192, 2.2788150639656557]\n[35.07135583350036, 7.828814774615411]\n[26.095976701399778, 2.0385857489333]\n[23.065125189341593, 4.490818451825372]\n[17.029386365926403, 10.370419435672128]\n[33.04542328371661, 6.08808298414478]\n[33.075670817082454, 6.015083645749996]\n[27.055498516937366, 0.8411380072082558]\n[33.25657829663178, 6.239378151849736]\n[29.103264421710495, 1.7840136442649863]\n[31.160872901765764, 3.9795354253785216]\n[32.14031735997639, 4.567423903679243]\n[36.29049462324811, 8.651854233424496]\nUpdated weight at epoch  6 are  [[ 0.          0.          0.          0.          0.        ]\n [28.046058    1.67681228  0.58287722  1.03492932  0.43806695]]\n[28.089143810376278, 1.386797075134461]\n[25.11971337416094, 3.314825184850135]\n[32.155870381627054, 4.283229801367695]\n[18.193405398660254, 10.152170209253303]\n[36.08323710533743, 8.198369409934314]\n[31.0322412983658, 3.1273645411845394]\n[19.05255888325765, 9.126978923602861]\n[24.186773244895647, 4.223704085911396]\n[25.099800796022265, 2.982741639125521]\n[20.223748416156685, 8.043617176177454]\n[22.20360331117452, 5.989284957222815]\n[32.0624390837628, 4.597275451793695]\n[27.09243436828813, 1.0641296818542452]\n[32.17141588429082, 4.724608984563868]\n[32.17141588429082, 4.548868906463482]\n[22.11334438749598, 5.861573751593434]\n[27.110883423451916, 1.161584368992048]\n[35.02855977627399, 7.4270194213435845]\n[32.09361307176243, 4.420348624144702]\n[33.03028912982749, 5.300137634353068]\n[21.02379604162864, 7.110960257147064]\n[27.03701166919155, 1.7170445117724467]\n[36.02776706930364, 8.210830958736741]\n[40.0374824383352, 12.07414930337001]\n[22.045407685048602, 6.2268694163800475]\n[19.05255888325765, 9.10750095057997]\n[26.095976701399778, 2.069782563271548]\n[32.14031735997639, 4.319437733973142]\n[27.110883423451916, 1.2038001196807042]\n[29.103264421710495, 2.2667349093029534]\n[29.103264421710495, 1.3824612558045526]\n[24.124676163629637, 4.4379544830741615]\n[26.13426869074396, 2.084819259181613]\n[29.086079144497972, 1.752528248159554]\n[20.149441679609886, 8.026764438789861]\n[28.231188426986208, 1.8647763351325892]\n[37.14835124201342, 9.35576994068721]\n[22.11334438749598, 6.077986789104911]\n[25.099800796022265, 3.4428703373312044]\n[25.099800796022265, 3.389075488310404]\n[26.038433132583073, 2.1880118187442967]\n[30.166206257996713, 2.6304260487916804]\n[25.03996805109783, 2.910073089831307]\n[21.142374511865974, 6.832122102197218]\n[26.057628441590765, 1.8171074152234958]\n[38.23610858861032, 10.673379600646912]\n[28.089143810376278, 0.8736926327458847]\n[20.074859899884732, 7.81533838053541]\n[18.05547008526779, 9.67170517862447]\n[31.144823004794873, 3.8438363067536034]\n[26.038433132583073, 1.804976937141253]\n[26.115129714401192, 2.441687832929984]\n[35.07135583350036, 7.566324896344234]\n[26.095976701399778, 2.1181092890665143]\n[23.065125189341593, 4.647683688952285]\n[17.029386365926403, 10.591242890011554]\n[33.04542328371661, 5.719116732337171]\n[33.075670817082454, 5.7411494729726344]\n[27.055498516937366, 0.9589612466066035]\n[33.25657829663178, 6.051762566996749]\n[29.103264421710495, 1.6929803149659415]\n[31.160872901765764, 3.908575418706103]\n[32.14031735997639, 4.547144486942007]\n[36.29049462324811, 8.70257509697114]\nUpdated weight at epoch  7 are  [[ 0.          0.          0.          0.          0.        ]\n [27.86336554  1.64412371  0.58314378  1.02115233  0.42257682]]\n[28.089143810376278, 1.3821486586169807]\n[25.11971337416094, 3.1480191531215045]\n[32.155870381627054, 4.434767298860903]\n[18.193405398660254, 9.96869332640523]\n[36.08323710533743, 8.30401596533967]\n[31.0322412983658, 3.2815000832413284]\n[19.05255888325765, 8.936697243566952]\n[24.186773244895647, 4.111787215183119]\n[25.099800796022265, 2.9006857472030405]\n[20.223748416156685, 7.985592882726814]\n[22.20360331117452, 5.996657110926397]\n[32.0624390837628, 4.542514972897547]\n[27.09243436828813, 1.0667382299992232]\n[32.17141588429082, 4.704191016783048]\n[32.17141588429082, 4.5699923184941]\n[22.11334438749598, 5.810333021045354]\n[27.110883423451916, 1.1576025769812155]\n[35.02855977627399, 7.421237907135825]\n[32.09361307176243, 4.473905918159197]\n[33.03028912982749, 5.3792032970962795]\n[21.02379604162864, 6.979302296919164]\n[27.03701166919155, 1.6659398293937984]\n[36.02776706930364, 8.277687827247952]\n[40.0374824383352, 12.203975457027822]\n[22.045407685048602, 6.00787616405794]\n[19.05255888325765, 8.936813163182926]\n[26.095976701399778, 1.9829423747069452]\n[32.14031735997639, 4.402456428544292]\n[27.110883423451916, 1.1007770561951193]\n[29.103264421710495, 2.2944333654060283]\n[29.103264421710495, 1.4745150854643492]\n[24.124676163629637, 4.320790378679825]\n[26.13426869074396, 1.9990674840295186]\n[29.086079144497972, 1.8094598573400575]\n[20.149441679609886, 7.944130252957559]\n[28.231188426986208, 1.8601671407382097]\n[37.14835124201342, 9.381170758058312]\n[22.11334438749598, 5.984788982023617]\n[25.099800796022265, 3.385680936121493]\n[25.099800796022265, 3.359230303808044]\n[26.038433132583073, 2.1865526385130347]\n[30.166206257996713, 2.615748938285716]\n[25.03996805109783, 2.901250904058422]\n[21.142374511865974, 6.846789473431053]\n[26.057628441590765, 1.8747992622668928]\n[38.23610858861032, 10.595658978148144]\n[28.089143810376278, 0.8603046250018433]\n[20.074859899884732, 7.808697527146565]\n[18.05547008526779, 9.72514682782142]\n[31.144823004794873, 3.7247510512316993]\n[26.038433132583073, 1.8863089702079276]\n[26.115129714401192, 2.520953082665692]\n[35.07135583350036, 7.441805793577621]\n[26.095976701399778, 2.1570754528523914]\n[23.065125189341593, 4.723972775897436]\n[17.029386365926403, 10.701635837708368]\n[33.04542328371661, 5.532733226844827]\n[33.075670817082454, 5.5981947813690605]\n[27.055498516937366, 1.032591486267387]\n[33.25657829663178, 5.946426546395895]\n[29.103264421710495, 1.6357229930237043]\n[31.160872901765764, 3.859946684453329]\n[32.14031735997639, 4.520952423573185]\n[36.29049462324811, 8.711791811131242]\nUpdated weight at epoch  8 are  [[ 0.          0.          0.          0.          0.        ]\n [27.78714373  1.63010499  0.58231145  1.01764466  0.41470904]]\n[28.089143810376278, 1.3850748405915685]\n[25.11971337416094, 3.0775398411723223]\n[32.155870381627054, 4.497934183549063]\n[18.193405398660254, 9.888741407823652]\n[36.08323710533743, 8.34610144366251]\n[31.0322412983658, 3.3497097647553695]\n[19.05255888325765, 8.850703695497536]\n[24.186773244895647, 4.063622207842777]\n[25.099800796022265, 2.866542101183525]\n[20.223748416156685, 7.963206837230087]\n[22.20360331117452, 6.006510661817285]\n[32.0624390837628, 4.509352677828815]\n[27.09243436828813, 1.0722286110652637]\n[32.17141588429082, 4.688154734962496]\n[32.17141588429082, 4.574184553561836]\n[22.11334438749598, 5.7910853345635145]\n[27.110883423451916, 1.1593143210622032]\n[35.02855977627399, 7.412585268037171]\n[32.09361307176243, 4.495070260952263]\n[33.03028912982749, 5.4135011924377245]\n[21.02379604162864, 6.91825658078015]\n[27.03701166919155, 1.6419226423254611]\n[36.02776706930364, 8.307193574268304]\n[40.0374824383352, 12.265367539660318]\n[22.045407685048602, 5.901014339804646]\n[19.05255888325765, 8.852786593907913]\n[26.095976701399778, 1.9404679104159748]\n[32.14031735997639, 4.4444329001765475]\n[27.110883423451916, 1.0508336532272666]\n[29.103264421710495, 2.3104803786861403]\n[29.103264421710495, 1.523282783597526]\n[24.124676163629637, 4.259531945253527]\n[26.13426869074396, 1.95309173626303]\n[29.086079144497972, 1.8404759554703787]\n[20.149441679609886, 7.8985535680074905]\n[28.231188426986208, 1.8596448577432807]\n[37.14835124201342, 9.398839207888333]\n[22.11334438749598, 5.933474375474389]\n[25.099800796022265, 3.3519437906336544]\n[25.099800796022265, 3.3388502602014922]\n[26.038433132583073, 2.1804003539098438]\n[30.166206257996713, 2.6138891687478147]\n[25.03996805109783, 2.891311301852852]\n[21.142374511865974, 6.8481430965327]\n[26.057628441590765, 1.898364011367851]\n[38.23610858861032, 10.562131903706804]\n[28.089143810376278, 0.8559449969643335]\n[20.074859899884732, 7.800482581145252]\n[18.05547008526779, 9.746915549466394]\n[31.144823004794873, 3.66951639359168]\n[26.038433132583073, 1.9243161033724376]\n[26.115129714401192, 2.5590064709406555]\n[35.07135583350036, 7.382183231054208]\n[26.095976701399778, 2.1755853521976323]\n[23.065125189341593, 4.760570477793802]\n[17.029386365926403, 10.75579971540033]\n[33.04542328371661, 5.440070814268151]\n[33.075670817082454, 5.526200189530096]\n[27.055498516937366, 1.0724141066003834]\n[33.25657829663178, 5.891735565566747]\n[29.103264421710495, 1.6049837471548296]\n[31.160872901765764, 3.8329547513707567]\n[32.14031735997639, 4.5044275810289065]\n[36.29049462324811, 8.712832763468283]\nUpdated weight at epoch  9 are  [[ 0.          0.          0.          0.          0.        ]\n [27.7524574   1.62364287  0.58171915  1.01670327  0.41073138]]\n[28.089143810376278, 1.3871473152026699]\n[25.11971337416094, 3.0451844016206993]\n[32.155870381627054, 4.5266005231349675]\n[18.193405398660254, 9.85149302521562]\n[36.08323710533743, 8.364615987538023]\n[31.0322412983658, 3.3816795239690958]\n[19.05255888325765, 8.809894144405465]\n[24.186773244895647, 4.0413921338782135]\n[25.099800796022265, 2.8511376398827077]\n[20.223748416156685, 7.953637395712564]\n[22.20360331117452, 6.0129622665702245]\n[32.0624390837628, 4.4913031369952225]\n[27.09243436828813, 1.0760738709381852]\n[32.17141588429082, 4.678616196231944]\n[32.17141588429082, 4.574595605015321]\n[22.11334438749598, 5.783167137705917]\n[27.110883423451916, 1.1611930371165993]\n[35.02855977627399, 7.406669651855244]\n[32.09361307176243, 4.504070041882881]\n[33.03028912982749, 5.429156353838114]\n[21.02379604162864, 6.889155897965636]\n[27.03701166919155, 1.6304111089286994]\n[36.02776706930364, 8.320717912342525]\n[40.0374824383352, 12.294923330506037]\n[22.045407685048602, 5.848511294577464]\n[19.05255888325765, 8.81138292557869]\n[26.095976701399778, 1.919718377132634]\n[32.14031735997639, 4.465247357608879]\n[27.110883423451916, 1.0265667055154966]\n[29.103264421710495, 2.318965795389288]\n[29.103264421710495, 1.5481109749806148]\n[24.124676163629637, 4.228499107644807]\n[26.13426869074396, 1.9295798817031178]\n[29.086079144497972, 1.856491021739357]\n[20.149441679609886, 7.874926333852434]\n[28.231188426986208, 1.8597988500065883]\n[37.14835124201342, 9.408713020263766]\n[22.11334438749598, 5.90681798319041]\n[25.099800796022265, 3.333944605694359]\n[25.099800796022265, 3.3274329951363635]\n[26.038433132583073, 2.176082578861168]\n[30.166206257996713, 2.614240786913664]\n[25.03996805109783, 2.885036909270371]\n[21.142374511865974, 6.8473860316043185]\n[26.057628441590765, 1.9088510844400832]\n[38.23610858861032, 10.54668026597986]\n[28.089143810376278, 0.8543825992839703]\n[20.074859899884732, 7.7951366166177865]\n[18.05547008526779, 9.75653153101352]\n[31.144823004794873, 3.6430104052801107]\n[26.038433132583073, 1.9425620237478998]\n[26.115129714401192, 2.577536171035102]\n[35.07135583350036, 7.3531187682761905]\n[26.095976701399778, 2.184513863425497]\n[23.065125189341593, 4.778380642497025]\n[17.029386365926403, 10.782515383988622]\n[33.04542328371661, 5.393980379482244]\n[33.075670817082454, 5.4901822751002936]\n[27.055498516937366, 1.092972013519322]\n[33.25657829663178, 5.863985890062586]\n[29.103264421710495, 1.5891881216028885]\n[31.160872901765764, 3.818866634109105]\n[32.14031735997639, 4.495383973399038]\n[36.29049462324811, 8.712525061621417]\nUpdated weight at epoch  10 are  [[ 0.          0.          0.          0.          0.        ]\n [27.73591926  1.62054315  0.58138681  1.01642924  0.40873093]]\n"
     ]
    }
   ],
   "source": [
    "trainedweights=SOM(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def SOMt(x,y,W):\n",
    "    #W=np.array([[0.8,0.7,0.2,0.2,0.1],[0.1,0.2,0.3,0.4,0.1]])\n",
    "    lr=0.5\n",
    "    d=[0,0]\n",
    "    e=1\n",
    "    res=np.zeros(y.shape)\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(W.shape[0]):\n",
    "          d[j]=np.sum((x[i,:]-W[j,:])**2)\n",
    "          d[j]=d[j]**0.5\n",
    "        if(d[0]<d[1]):\n",
    "          t=0\n",
    "          res[i]=0\n",
    "        else:\n",
    "          t=1\n",
    "          res[i]=1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predtrain=SOMt(X_train,y_train,trainedweights)\n",
    "y_predtest=SOMt(X_test,y_test,trainedweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of training data:59.375\nAccuracy of testing data:50.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of training data:'+str(accuracy_score(y_train,y_predtrain)*100))\n",
    "print('Accuracy of testing data:'+str(accuracy_score(y_test,y_predtest)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.7 64-bit",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "29f46617368d3161804a08cc10060689ada2119971041ea0c2e47b3f4f2b6248"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}